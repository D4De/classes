{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys \n",
    "\n",
    "CLASSES_MODULE_PATH = \"../../\"\n",
    "WEIGHT_FILE_PATH = \"./\"\n",
    "MODELS_FOLDER = CLASSES_MODULE_PATH + 'models'\n",
    "\n",
    "# appending a path\n",
    "sys.path.append(CLASSES_MODULE_PATH) #CHANGE THIS LINE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (tanh1): Tanh()\n",
       "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (tanh2): Tanh()\n",
       "  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (tanh3): Tanh()\n",
       "  (linear1): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (tanh4): Tanh()\n",
       "  (linear2): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from examples.pytorch.lenet import LeNet5\n",
    "\n",
    "N_CLASSES = 10\n",
    "\n",
    "# Load the original model\n",
    "model = LeNet5(N_CLASSES)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transf = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
    "\n",
    "test_dataset = datasets.MNIST('data', train=False, transform=transf, download=True)\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94587e7ae5c0455b8dbd3f4248c00710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Experiments with the layer vulernability factor\n",
    "from examples.pytorch.lenet import LeNet5Simulator\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "N_INJECTABLE_LAYERS = 1\n",
    "N_IMAGES = 10000\n",
    "N_SIM_PER_IMAGE = 1\n",
    "\n",
    "fault_robust_runs_by_layer= defaultdict(int)\n",
    "correct_classifications = defaultdict(int)\n",
    "\n",
    "test_images = np.random.choice(len(test_dataset), size=N_IMAGES, replace=False).astype(int)\n",
    "images_results = {}\n",
    "layer_results = {}\n",
    "\n",
    "prog_bar = tqdm(total=N_INJECTABLE_LAYERS * N_IMAGES * N_SIM_PER_IMAGE)\n",
    "\n",
    "for image_idx in test_images:\n",
    "    img, label = test_dataset[image_idx]\n",
    "    img = img.unsqueeze(0)\n",
    "    output_vanilla = model(img)[0]\n",
    "    pred_vanilla = output_vanilla.argmax(dim=1).item()\n",
    "    images_results[image_idx] = {\n",
    "        \"label\": label,\n",
    "        \"golden_prediction\": pred_vanilla,\n",
    "    }\n",
    "\n",
    "for injectable_layer_id in range(N_INJECTABLE_LAYERS):\n",
    "    error_simuator_net = LeNet5Simulator(N_CLASSES, selected_layer=injectable_layer_id)\n",
    "    error_simuator_net.eval()\n",
    "\n",
    "    images = {}\n",
    "    for image_idx in test_images:\n",
    "        label = images_results[image_idx][\"label\"]\n",
    "        pred_vanilla = images_results[image_idx][\"golden_prediction\"] \n",
    "        images[image_idx] = {\n",
    "            \"label\": label,\n",
    "            \"golden_prediction\": pred_vanilla,\n",
    "            \"results\": defaultdict(int),\n",
    "        }\n",
    "        for run in range(N_SIM_PER_IMAGE):\n",
    "            output_corr = error_simuator_net(img)[0]\n",
    "            # print(f'The shape is {img.shape}')\n",
    "            pred = output_corr.argmax(dim=1).item()\n",
    "            # print(f\" Pred vs Label => ({pred},{label})\")\n",
    "            images[image_idx][\"results\"][pred] += 1\n",
    "\n",
    "            prog_bar.update(1)\n",
    "    layer_results[injectable_layer_id] = {\n",
    "        \"images\": images\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.0801\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "# with open(\"lvf_campaign.json\", \"w\") as f:\n",
    "#     json.dump(layer_results, f)\n",
    "\n",
    "accuracy = sum(1 for v in images_results.values() if v[\"label\"] == v[\"golden_prediction\"]) / N_IMAGES\n",
    "print(images_results)\n",
    "print(f'{accuracy=}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
